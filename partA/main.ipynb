{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading datasets"
      ],
      "metadata": {
        "id": "DyoRX3lFStCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
        "!unzip -q nature_12K.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ilqPOfecgBE",
        "outputId": "ae449f6e-a692-4a60-b801-fc2a4b987973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-19 04:04:38--  https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.143.207, 173.194.69.207, 173.194.79.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.143.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3816687935 (3.6G) [application/zip]\n",
            "Saving to: ‘nature_12K.zip’\n",
            "\n",
            "nature_12K.zip      100%[===================>]   3.55G  40.2MB/s    in 93s     \n",
            "\n",
            "2025-04-19 04:06:11 (39.3 MB/s) - ‘nature_12K.zip’ saved [3816687935/3816687935]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART A : Training CNN from Scratch"
      ],
      "metadata": {
        "id": "t8i8DqR9QQes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import wandb\n",
        "\n",
        "# === Utility ===\n",
        "def get_activation(name):\n",
        "    activations = {\n",
        "        'relu': nn.ReLU(),\n",
        "        'gelu': nn.GELU(),\n",
        "        'silu': nn.SiLU(),\n",
        "        'mish': nn.Mish(),\n",
        "    }\n",
        "    return activations.get(name.lower(), nn.ReLU())"
      ],
      "metadata": {
        "id": "cElXr9dpNZMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1: Building the CNN Model"
      ],
      "metadata": {
        "id": "NxhmNV9DNE-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation:\n",
        "\n",
        "*   This implements a flexible CNN with configurable:\n",
        "  *   Number of convolutional layers (conv_layers)\n",
        "  *   Filters per layer (filters_per_layer)\n",
        "  *   Kernel size (kernel_size)\n",
        "  *   Activation functions (activation)\n",
        "  *   Dense layer neurons (dense_neurons)\n",
        "\n",
        "*   Each conv block contains:\n",
        "  *   Convolutional layer with padding to maintain spatial dimensions\n",
        "  *   Activation function (ReLU, GELU, SiLU, or Mish)\n",
        "  *   Max pooling with 2x2 window\n",
        "\n",
        "*   The model ends with:\n",
        "  *   Flattening layer\n",
        "\n",
        "  *   One dense layer with ReLU activation\n",
        "\n",
        "  *   Output layer with neurons equal to number of classes\n",
        "\n",
        "To answer the question about computations and parameters:\n",
        "\n",
        "1. Total computations = Sum of (operations in each conv layer) + (operations in dense layer)\n",
        "\n",
        "2. Total parameters = Sum of (weights in conv layers) + (weights in dense layers)"
      ],
      "metadata": {
        "id": "pyJs2fk4NdrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCNN(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_channels=3,\n",
        "        num_classes=10,\n",
        "        conv_layers=3,\n",
        "        filters_per_layer=[32, 64, 128],\n",
        "        kernel_size=3,\n",
        "        activation='relu',\n",
        "        dense_neurons=256,\n",
        "        input_size=(64, 64)\n",
        "    ):\n",
        "        super(CustomCNN, self).__init__()\n",
        "\n",
        "        self.conv_blocks = nn.Sequential()\n",
        "        in_channels = input_channels\n",
        "        height, width = input_size\n",
        "\n",
        "        for i in range(conv_layers):\n",
        "            out_channels = filters_per_layer[i]\n",
        "            self.conv_blocks.append(nn.Conv2d(in_channels, out_channels, kernel_size, padding=1))\n",
        "            self.conv_blocks.append(get_activation(activation))\n",
        "            self.conv_blocks.append(nn.MaxPool2d(kernel_size=2))\n",
        "            in_channels = out_channels\n",
        "            height //= 2\n",
        "            width //= 2\n",
        "\n",
        "        self.flattened_size = in_channels * height * width\n",
        "        self.fc1 = nn.Linear(self.flattened_size, dense_neurons)\n",
        "        self.fc_out = nn.Linear(dense_neurons, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_blocks(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc_out(x)"
      ],
      "metadata": {
        "id": "KLitZgWZNHFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2: Training and Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "PCW2NucZOMOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation:\n",
        "\n",
        "*   Training process:\n",
        "  *   Batches are loaded and sent to the appropriate device (CPU/GPU)\n",
        "  *   Forward pass, loss calculation, backpropagation\n",
        "  *   Metrics logged to Weights & Biases (wandb)\n",
        "\n",
        "*   Validation:\n",
        "  *   Model set to evaluation mode\n",
        "  *   No gradient calculation for faster inference\n",
        "  *   Accuracy and loss calculated on validation set\n",
        "\n",
        "*   Hyperparameters being tuned:\n",
        "  *   Number of filters (32, 64, 128)\n",
        "  *   Activation functions (ReLU, GELU, SiLU, Mish)\n",
        "  *   Filter organization (same, doubling, halving)\n",
        "  *   Batch normalization (present in enhanced version)\n",
        "  *   Dropout (present in enhanced version)"
      ],
      "metadata": {
        "id": "yAPmgwWFOQCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=10):\n",
        "    model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss, correct = 0.0, 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        acc = correct / len(train_loader.dataset)\n",
        "        wandb.log({\"train_loss\": running_loss / len(train_loader), \"train_acc\": acc, \"epoch\": epoch})\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss, val_correct = 0.0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        val_acc = val_correct / len(val_loader.dataset)\n",
        "        wandb.log({\"val_loss\": val_loss / len(val_loader), \"val_acc\": val_acc})\n",
        "        print(f\"Epoch {epoch+1}, Val Acc: {val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "fblq5ev2OL4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3: Observations from Plots"
      ],
      "metadata": {
        "id": "ATUqHYxLOuFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code that generates the plots:\n",
        "The wandb.log() calls throughout the training process automatically generate:\n",
        "\n",
        "*   Accuracy vs epoch plots\n",
        "*   Loss vs epoch plots\n",
        "*   Parallel coordinates plots\n",
        "*   Correlation summary tables\n",
        "\n",
        "Key observations to make:\n",
        "1. How different activation functions affect training\n",
        "2. Impact of increasing filter numbers\n",
        "3. Effect of different filter organization patterns\n",
        "4. How batch normalization affects training stability\n",
        "5. Effect of dropout on overfitting"
      ],
      "metadata": {
        "id": "Sl3lCOnROrxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4: Testing the Best Model"
      ],
      "metadata": {
        "id": "aQnVegRDO7ox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation:\n",
        "\n",
        "*   After hyperparameter tuning, select the best model\n",
        "*   configuration\n",
        "*   Evaluate on the untouched test set\n",
        "*   Generate 10×3 grid of sample images with predictions\n",
        "*   Visualize filters from first convolutional layer"
      ],
      "metadata": {
        "id": "j_uMKLDzPAE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In the enhanced version, this would be added:\n",
        "def evaluate_test_set(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# And to visualize predictions:\n",
        "# def visualize_predictions(model, test_loader, class_names, num_samples=10):\n",
        "    # Implementation as shown in enhanced version"
      ],
      "metadata": {
        "id": "lGTbO3vWO9ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5: GitHub Submission"
      ],
      "metadata": {
        "id": "W3sju7rlPKkb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Done ✅"
      ],
      "metadata": {
        "id": "ZRtMYmnePIUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Execution"
      ],
      "metadata": {
        "id": "66JIx6L7POdU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation:\n",
        "\n",
        "1. Initializes wandb for experiment tracking\n",
        "2. Sets up data transformations and loading\n",
        "3. Creates 80/20 train/validation split\n",
        "4. Initializes model with configurable parameters\n",
        "5. Sets up loss function and optimizer\n",
        "6. Starts training process"
      ],
      "metadata": {
        "id": "88zMFn74Qx6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run():\n",
        "    wandb.init(project=\"da6401-assignment2\", config={\n",
        "        \"conv_layers\": 3,\n",
        "        \"filters\": [32, 64, 128],\n",
        "        \"kernel_size\": 3,\n",
        "        \"activation\": \"relu\",\n",
        "        \"dense_neurons\": 256,\n",
        "        \"batch_size\": 64,\n",
        "        \"epochs\": 10,\n",
        "        \"lr\": 1e-3\n",
        "    })\n",
        "    config = wandb.config\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    dataset = datasets.ImageFolder(\"./inaturalist_12K/train\", transform=transform)\n",
        "    val_size = int(0.2 * len(dataset))\n",
        "    train_size = len(dataset) - val_size\n",
        "    train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=config.batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=config.batch_size)\n",
        "\n",
        "    model = CustomCNN(\n",
        "        conv_layers=config.conv_layers,\n",
        "        filters_per_layer=config.filters,\n",
        "        kernel_size=config.kernel_size,\n",
        "        activation=config.activation,\n",
        "        dense_neurons=config.dense_neurons,\n",
        "        input_size=(64, 64)\n",
        "    )\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_model(model, train_loader, val_loader, optimizer, criterion, device, config.epochs)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run()\n",
        "\n",
        "# ed57ccb8a48835266e803f637f8b571506709c5d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "gXQQblrNPPap",
        "outputId": "33a7e272-68ff-49d1-f78d-f7c7331571a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myogesh084arya\u001b[0m (\u001b[33myogesh084arya-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250419_041215-zarq4lx9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yogesh084arya-indian-institute-of-technology-madras/DA6401-Assignment2/runs/zarq4lx9' target=\"_blank\">astral-brook-8</a></strong> to <a href='https://wandb.ai/yogesh084arya-indian-institute-of-technology-madras/DA6401-Assignment2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yogesh084arya-indian-institute-of-technology-madras/DA6401-Assignment2' target=\"_blank\">https://wandb.ai/yogesh084arya-indian-institute-of-technology-madras/DA6401-Assignment2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yogesh084arya-indian-institute-of-technology-madras/DA6401-Assignment2/runs/zarq4lx9' target=\"_blank\">https://wandb.ai/yogesh084arya-indian-institute-of-technology-madras/DA6401-Assignment2/runs/zarq4lx9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Val Acc: 0.2316\n",
            "Epoch 2, Val Acc: 0.2481\n",
            "Epoch 3, Val Acc: 0.2596\n",
            "Epoch 4, Val Acc: 0.3002\n",
            "Epoch 5, Val Acc: 0.3112\n",
            "Epoch 6, Val Acc: 0.2911\n",
            "Epoch 7, Val Acc: 0.3132\n",
            "Epoch 8, Val Acc: 0.3252\n",
            "Epoch 9, Val Acc: 0.3222\n",
            "Epoch 10, Val Acc: 0.3137\n"
          ]
        }
      ]
    }
  ]
}