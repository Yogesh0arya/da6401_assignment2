{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading datasets"
      ],
      "metadata": {
        "id": "DyoRX3lFStCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
        "!unzip -q nature_12K.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ilqPOfecgBE",
        "outputId": "ae449f6e-a692-4a60-b801-fc2a4b987973"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-19 04:04:38--  https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.143.207, 173.194.69.207, 173.194.79.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.143.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3816687935 (3.6G) [application/zip]\n",
            "Saving to: ‘nature_12K.zip’\n",
            "\n",
            "nature_12K.zip      100%[===================>]   3.55G  40.2MB/s    in 93s     \n",
            "\n",
            "2025-04-19 04:06:11 (39.3 MB/s) - ‘nature_12K.zip’ saved [3816687935/3816687935]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART B : Fine-tuning a Pre-trained Model"
      ],
      "metadata": {
        "id": "PHSoSnXqRiId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import wandb\n",
        "\n",
        "# === Fine-tuning Pretrained Model ===\n",
        "def get_dataloaders(data_dir, batch_size=32):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "    val_size = int(0.2 * len(full_dataset))\n",
        "    train_size = len(full_dataset) - val_size\n",
        "    train_set, val_set = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=batch_size)\n",
        "\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "ABuWpF_uRzSk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1: Loading and Modifying Pre-trained Model"
      ],
      "metadata": {
        "id": "KDAENraNRhES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation:\n",
        "\n",
        "- Loads ResNet50 pre-trained on ImageNet\n",
        "\n",
        "- Handles two key requirements:\n",
        "\n",
        "  1. Image Size Compatibility: Uses standard 224x224 input size via transforms.Resize()\n",
        "\n",
        "  2. Output Layer Modification: Replaces final layer (1000 classes) with new layer (10 classes)\n",
        "\n",
        "- Provides three freezing strategies:\n",
        "\n",
        "  - full: Freeze all layers except final\n",
        "\n",
        "  - partial: Freeze layers until specified index\n",
        "\n",
        "  - (implied none): No freezing, fine-tune all layers"
      ],
      "metadata": {
        "id": "wn3_eofiRmFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_model(num_classes=10, freeze_type=\"partial\", freeze_until=6):\n",
        "    model = models.resnet50(pretrained=True)\n",
        "\n",
        "    if freeze_type == \"full\":\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "    elif freeze_type == \"partial\":\n",
        "        for i, (name, param) in enumerate(model.named_parameters()):\n",
        "            if i < freeze_until:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features, num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "Ejn5sk-RRv-p"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2: Fine-tuning Strategies"
      ],
      "metadata": {
        "id": "pX3QIP5dR1tD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code implements three strategies through freeze_type:\n",
        "\n",
        "1. Full Freezing (freeze_type=\"full\"):\n",
        "\n",
        "  - All layers frozen except final classification layer\n",
        "\n",
        "  - Only trains the new output layer\n",
        "\n",
        "2. Partial Freezing (freeze_type=\"partial\"):\n",
        "\n",
        "  - Freezes layers up to freeze_until index\n",
        "\n",
        "  - Fine-tunes later layers and final classifier\n",
        "\n",
        "  - Common to freeze early feature extractors\n",
        "\n",
        "3. No Freezing (implied when freeze_type is neither):\n",
        "\n",
        "  - All layers are trainable\n",
        "\n",
        "  - Complete fine-tuning of entire network\n",
        "\n",
        "Key Trick: Using param.requires_grad = False to freeze layers and reduce computation"
      ],
      "metadata": {
        "id": "s_27k8NoR3uk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3: Fine-tuning Experiments"
      ],
      "metadata": {
        "id": "9XR3n03bSD-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Insights to Compare:\n",
        "\n",
        "1. Training Speed: Frozen layers train faster\n",
        "\n",
        "2. Accuracy: Partial freezing often gives best balance\n",
        "\n",
        "3. Overfitting: Full freezing may underfit, no freezing may overfit\n",
        "\n",
        "4. Resource Usage: More frozen layers = less memory/computation"
      ],
      "metadata": {
        "id": "KcjvZK8mSHek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_finetune(model, train_loader, val_loader, device, epochs=5, lr=1e-4):\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # Only optimize parameters that require gradients\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss, correct = 0.0, 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        train_acc = correct / len(train_loader.dataset)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss, val_correct = 0.0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "        val_acc = val_correct / len(val_loader.dataset)\n",
        "\n",
        "        wandb.log({\n",
        "            \"train_loss\": total_loss / len(train_loader),\n",
        "            \"train_acc\": train_acc,\n",
        "            \"val_loss\": val_loss / len(val_loader),\n",
        "            \"val_acc\": val_acc,\n",
        "            \"epoch\": epoch\n",
        "        })"
      ],
      "metadata": {
        "id": "JBEquE3SSFg3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Execution"
      ],
      "metadata": {
        "id": "hyNPfwyySMZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run():\n",
        "    wandb.init(project=\"da6401-assignment2\", config={\n",
        "        \"epochs\": 5,\n",
        "        \"lr\": 1e-4,\n",
        "        \"batch_size\": 32,\n",
        "        \"freeze_type\": \"partial\",  # full, partial, none\n",
        "        \"freeze_until\": 6,\n",
        "    })\n",
        "    config = wandb.config\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    train_loader, val_loader = get_dataloaders(\"./inaturalist_12K/train\", config.batch_size)\n",
        "\n",
        "    model = modify_model(num_classes=10,\n",
        "                         freeze_type=config.freeze_type,\n",
        "                         freeze_until=config.freeze_until)\n",
        "\n",
        "    train_finetune(model, train_loader, val_loader, device, config.epochs, config.lr)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "_8Sykx5nt7hB",
        "outputId": "a371edf0-6d61-49c2-c447-9961eec0e14c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">absurd-voice-6</strong> at: <a href='https://wandb.ai/yogesh084arya-indian-institute-of-technology-madras/DA6401-Assignment2/runs/jouznsi5' target=\"_blank\">https://wandb.ai/yogesh084arya-indian-institute-of-technology-madras/DA6401-Assignment2/runs/jouznsi5</a><br> View project at: <a href='https://wandb.ai/yogesh084arya-indian-institute-of-technology-madras/DA6401-Assignment2' target=\"_blank\">https://wandb.ai/yogesh084arya-indian-institute-of-technology-madras/DA6401-Assignment2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250418_114532-jouznsi5/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250418_114602-mes6bntx</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yogesh084arya-indian-institute-of-technology-madras/DA6401-Assignment2/runs/mes6bntx' target=\"_blank\">absurd-tree-7</a></strong> to <a href='https://wandb.ai/yogesh084arya-indian-institute-of-technology-madras/DA6401-Assignment2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yogesh084arya-indian-institute-of-technology-madras/DA6401-Assignment2' target=\"_blank\">https://wandb.ai/yogesh084arya-indian-institute-of-technology-madras/DA6401-Assignment2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yogesh084arya-indian-institute-of-technology-madras/DA6401-Assignment2/runs/mes6bntx' target=\"_blank\">https://wandb.ai/yogesh084arya-indian-institute-of-technology-madras/DA6401-Assignment2/runs/mes6bntx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 91.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc: 0.6841, Val Acc: 0.7674\n",
            "Epoch 2: Train Acc: 0.8675, Val Acc: 0.7654\n",
            "Epoch 3: Train Acc: 0.9374, Val Acc: 0.7579\n",
            "Epoch 4: Train Acc: 0.9607, Val Acc: 0.7499\n",
            "Epoch 5: Train Acc: 0.9633, Val Acc: 0.7514\n"
          ]
        }
      ]
    }
  ]
}